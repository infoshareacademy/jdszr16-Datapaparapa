import streamlit as st
import pandas as pd
from sklearn.feature_extraction.text import CountVectorizer
from mlxtend.frequent_patterns import apriori, association_rules


# TytuÅ‚ strony
st.title("ğŸ“Š Analiza Koszykowa")

# Sprawdzenie, czy plik zostaÅ‚ wgrany
if 'df_sales' not in st.session_state:
    st.warning("ğŸš« ProszÄ™ wgraÄ‡ plik CSV na stronie gÅ‚Ã³wnej.")
    st.stop()

df_sales = st.session_state['df_sales']


# Funkcja do tworzenia gÄ™stej macierzy
def create_dense_matrix(data, column):
    grouped_data = data.groupby('user_id')[column].apply(lambda x: ' '.join(map(str, x.unique())))
    vectorizer = CountVectorizer(binary=True, dtype=bool)
    sparse_matrix = vectorizer.fit_transform(grouped_data.astype(str))
    return pd.DataFrame(sparse_matrix.toarray(), columns=vectorizer.get_feature_names_out())


# Funkcja do generowania reguÅ‚ asocjacyjnych
def generate_association_rules(data_df, min_support, min_confidence):
    frequent_itemsets = apriori(data_df, min_support=min_support, use_colnames=True)
    if frequent_itemsets.empty:
        return pd.DataFrame()  # ZwrÃ³Ä‡ pustÄ… ramkÄ™ danych, jeÅ›li brak wynikÃ³w
    rules = association_rules(frequent_itemsets, metric="confidence", min_threshold=min_confidence)
    rules['antecedents'] = rules['antecedents'].apply(lambda x: ', '.join(list(x)))
    rules['consequents'] = rules['consequents'].apply(lambda x: ', '.join(list(x)))
    return rules


# Funkcja do zmiany nazw kolumn i skalowania do procentÃ³w
COLUMN_MAPPING = {
    "antecedents": "Produkty bazowe",
    "consequents": "Produkty rekomendowane",
    "antecedent support": "PopularnoÅ›Ä‡ produktÃ³w bazowych",
    "consequent support": "PopularnoÅ›Ä‡ produktÃ³w rekomendowanych",
    "support": "Wsparcie reguÅ‚y",
    "confidence": "PewnoÅ›Ä‡ reguÅ‚y",
    "lift": "Wzrost sprzedaÅ¼y",
    "leverage": "WkÅ‚ad reguÅ‚y w sprzedaÅ¼",
    "conviction": "SiÅ‚a zaleÅ¼noÅ›ci",
    "zhangs_metric": "Waga reguÅ‚y"
}


def rename_and_scale_columns(rules):
    rules = rules.rename(columns=COLUMN_MAPPING)
    # Skalowanie wybranych kolumn do procentÃ³w
    percentage_columns = [
        "PopularnoÅ›Ä‡ produktÃ³w bazowych",
        "PopularnoÅ›Ä‡ produktÃ³w rekomendowanych",
        "Wsparcie reguÅ‚y",
        "PewnoÅ›Ä‡ reguÅ‚y"
    ]
    rules[percentage_columns] = rules[percentage_columns] * 100
    return rules


# Funkcja do formatowania kolumn procentowych
def format_percent(df, columns):
    df_formatted = df.copy()
    for col in columns:
        df_formatted[col] = df_formatted[col].map(lambda x: f"{x:.2f}%")
    return df_formatted


# Sekcja wyboru analizy
analysis_type = st.selectbox(
    "ğŸ” Wybierz rodzaj analizy:",
    ("Produkty", "Marki", "Kategorie")
)

# Przycisk do uruchomienia analizy
if st.button("ğŸ” PrzeprowadÅº analizÄ™ koszykowÄ…"):
    # Dopasowanie danych do wyboru uÅ¼ytkownika
    column_mapping_analysis = {
        "Produkty": "product_id",
        "Marki": "brand",
        "Kategorie": "category_id"
    }

    selected_column = column_mapping_analysis.get(analysis_type)

    if selected_column in df_sales.columns:
        analysis_data = df_sales[df_sales['event_type'] == 'purchase'][['user_id', selected_column]].dropna()
        analysis_data[selected_column] = analysis_data[selected_column].astype(str)
        dense_matrix = create_dense_matrix(analysis_data, selected_column)

        # Generowanie reguÅ‚ asocjacyjnych
        association_rules_result = generate_association_rules(dense_matrix, min_support=0.002, min_confidence=0.01)

        if not association_rules_result.empty:
            # Zmiana nazw kolumn i skalowanie
            association_rules_result = rename_and_scale_columns(association_rules_result)

            # Przechowanie wynikÃ³w w session_state
            st.session_state['association_rules_result'] = association_rules_result
            st.session_state['analysis_done_koszykowa'] = True

            st.success("âœ… Analiza koszykowa zostaÅ‚a przeprowadzona pomyÅ›lnie!")
        else:
            st.warning(f"âš ï¸ Brak reguÅ‚ asocjacyjnych dla {analysis_type.lower()} przy podanych parametrach.")
            st.session_state['association_rules_result'] = None
            st.session_state['analysis_done_koszykowa'] = False
    else:
        st.error(f"âŒ Plik nie zawiera wymaganej kolumny: '{selected_column}'.")
        st.session_state['association_rules_result'] = None
        st.session_state['analysis_done_koszykowa'] = False

# WyÅ›wietlanie wynikÃ³w analizy koszykowej
if 'analysis_done_koszykowa' in st.session_state and st.session_state['analysis_done_koszykowa']:
    association_rules_result = st.session_state['association_rules_result']

    # Sekcja wyboru kolumn
    st.write("### ğŸ“‹ Wybierz kolumny do wyÅ›wietlenia:")
    all_columns = list(COLUMN_MAPPING.values())

    # Inicjalizacja session_state dla wybranych kolumn, jeÅ›li nie istnieje
    if 'selected_columns_koszykowa' not in st.session_state:
        st.session_state['selected_columns_koszykowa'] = all_columns.copy()


    # Funkcja resetujÄ…ca wybÃ³r kolumn
    def reset_columns_koszykowa():
        st.session_state['selected_columns_koszykowa'] = all_columns.copy()


    # Przycisk resetujÄ…cy wybÃ³r kolumn
    st.button("ğŸ”„ PrzywrÃ³Ä‡ wszystkie kolumny", on_click=reset_columns_koszykowa)

    # Multiselect dla wyboru kolumn, z wartoÅ›ciÄ… domyÅ›lnÄ… z session_state
    selected_columns = st.multiselect(
        "ğŸ—‚ï¸ Wybierz kolumny:",
        options=all_columns,
        default=st.session_state['selected_columns_koszykowa'],
        key='multiselect_columns_koszykowa'
    )

    # Aktualizacja session_state z wybranymi kolumnami
    if selected_columns:
        st.session_state['selected_columns_koszykowa'] = selected_columns

        # Dodanie sekcji filtrÃ³w na gÅ‚Ã³wnej stronie
        st.header("ğŸ” Filtry poszczegÃ³lnych wartoÅ›ci kolumn")

        # Ustal zakresy dla suwakÃ³w na podstawie danych
        min_antecedent_support = float(association_rules_result["PopularnoÅ›Ä‡ produktÃ³w bazowych"].min())
        max_antecedent_support = float(association_rules_result["PopularnoÅ›Ä‡ produktÃ³w bazowych"].max())
        antecedent_support_range = st.slider(
            "PopularnoÅ›Ä‡ produktÃ³w bazowych (%)",
            min_value=0.0,
            max_value=100.0,
            value=(min_antecedent_support, max_antecedent_support),
            step=0.1
        )

        min_consequent_support = float(association_rules_result["PopularnoÅ›Ä‡ produktÃ³w rekomendowanych"].min())
        max_consequent_support = float(association_rules_result["PopularnoÅ›Ä‡ produktÃ³w rekomendowanych"].max())
        consequent_support_range = st.slider(
            "PopularnoÅ›Ä‡ produktÃ³w rekomendowanych (%)",
            min_value=0.0,
            max_value=100.0,
            value=(min_consequent_support, max_consequent_support),
            step=0.1
        )

        min_support_val = float(association_rules_result["Wsparcie reguÅ‚y"].min())
        max_support_val = float(association_rules_result["Wsparcie reguÅ‚y"].max())
        support_range = st.slider(
            "Wsparcie reguÅ‚y (%)",
            min_value=0.0,
            max_value=100.0,
            value=(min_support_val, max_support_val),
            step=0.1
        )

        min_confidence_val = float(association_rules_result["PewnoÅ›Ä‡ reguÅ‚y"].min())
        max_confidence_val = float(association_rules_result["PewnoÅ›Ä‡ reguÅ‚y"].max())
        confidence_range = st.slider(
            "PewnoÅ›Ä‡ reguÅ‚y (%)",
            min_value=0.0,
            max_value=100.0,
            value=(min_confidence_val, max_confidence_val),
            step=0.1
        )

        min_lift = float(association_rules_result["Wzrost sprzedaÅ¼y"].min())
        max_lift = float(association_rules_result["Wzrost sprzedaÅ¼y"].max())
        lift_range = st.slider(
            "Wzrost sprzedaÅ¼y",
            min_value=min_lift,
            max_value=max_lift,
            value=(min_lift, max_lift),
            step=0.1
        )

        # Filtracja danych na podstawie suwakÃ³w
        filtered_rules = association_rules_result[
            (association_rules_result["PopularnoÅ›Ä‡ produktÃ³w bazowych"] >= antecedent_support_range[0]) &
            (association_rules_result["PopularnoÅ›Ä‡ produktÃ³w bazowych"] <= antecedent_support_range[1]) &
            (association_rules_result["PopularnoÅ›Ä‡ produktÃ³w rekomendowanych"] >= consequent_support_range[0]) &
            (association_rules_result["PopularnoÅ›Ä‡ produktÃ³w rekomendowanych"] <= consequent_support_range[1]) &
            (association_rules_result["Wsparcie reguÅ‚y"] >= support_range[0]) &
            (association_rules_result["Wsparcie reguÅ‚y"] <= support_range[1]) &
            (association_rules_result["PewnoÅ›Ä‡ reguÅ‚y"] >= confidence_range[0]) &
            (association_rules_result["PewnoÅ›Ä‡ reguÅ‚y"] <= confidence_range[1]) &
            (association_rules_result["Wzrost sprzedaÅ¼y"] >= lift_range[0]) &
            (association_rules_result["Wzrost sprzedaÅ¼y"] <= lift_range[1])
            ]

        # Opcjonalne formatowanie kolumn procentowych z znakiem %
        filtered_rules_display = format_percent(filtered_rules, [
            "PopularnoÅ›Ä‡ produktÃ³w bazowych",
            "PopularnoÅ›Ä‡ produktÃ³w rekomendowanych",
            "Wsparcie reguÅ‚y",
            "PewnoÅ›Ä‡ reguÅ‚y"
        ])

        st.write("### ğŸ“ˆ Wyniki analizy koszykowej (po filtracji):")
        st.dataframe(filtered_rules_display[selected_columns])

        # Dodanie przycisku do pobrania filtrowanych danych
        # Pobieramy dane z wybranymi kolumnami
        filtered_selected = filtered_rules[selected_columns]
        csv = filtered_selected.to_csv(index=False, encoding='utf-8-sig').encode('utf-8-sig')  # Dodanie BOM

        st.download_button(
            label="ğŸ“¥ Pobierz dane jako CSV",
            data=csv,
            file_name='filtered_rules.csv',
            mime='text/csv'
        )


    else:
        st.warning("âš ï¸ Wybierz przynajmniej jednÄ… kolumnÄ™ do wyÅ›wietlenia.")

    # Dodanie Dokumentacji Kolumn
    with st.expander("ğŸ“„ Dokumentacja Kolumn"):
        st.markdown("""
        ### Produkty bazowe (antecedents)
        Produkty, ktÃ³re klienci kupujÄ… w pierwszej kolejnoÅ›ci.

        ### Produkty rekomendowane (consequents)
        Produkty, ktÃ³re najczÄ™Å›ciej sÄ… kupowane razem z produktami bazowymi.

        ### PopularnoÅ›Ä‡ produktÃ³w bazowych (antecedent support)
        CzÄ™stoÅ›Ä‡ wystÄ™powania produktÃ³w bazowych w transakcjach.

        ### PopularnoÅ›Ä‡ produktÃ³w rekomendowanych (consequent support)
        CzÄ™stoÅ›Ä‡ wystÄ™powania produktÃ³w rekomendowanych w transakcjach.

        ### Wsparcie reguÅ‚y (support)
        Odsetek transakcji zawierajÄ…cych zarÃ³wno produkty bazowe, jak i rekomendowane.

        ### PewnoÅ›Ä‡ reguÅ‚y (confidence)
        PrawdopodobieÅ„stwo, Å¼e klient kupi produkt rekomendowany, jeÅ›li kupiÅ‚ produkt bazowy.

        ### Wzrost sprzedaÅ¼y (lift)
        Ile razy wiÄ™ksze jest prawdopodobieÅ„stwo zakupu produktu rekomendowanego w porÃ³wnaniu do przypadku losowego.

        ### WkÅ‚ad reguÅ‚y w sprzedaÅ¼ (leverage)
        Miara zwiÄ™kszenia sprzedaÅ¼y dziÄ™ki tej regule w porÃ³wnaniu do przypadkowego wspÃ³Å‚wystÄ™powania.

        ### SiÅ‚a zaleÅ¼noÅ›ci (conviction)
        Jak bardzo zakup produktu rekomendowanego zaleÅ¼y od zakupu produktu bazowego.

        ### Waga reguÅ‚y (zhangs_metric)
        Miara rÃ³wnowagi miÄ™dzy wsparciem a pewnoÅ›ciÄ… reguÅ‚y, pomagajÄ…ca wybraÄ‡ najbardziej istotne reguÅ‚y.
        """)


